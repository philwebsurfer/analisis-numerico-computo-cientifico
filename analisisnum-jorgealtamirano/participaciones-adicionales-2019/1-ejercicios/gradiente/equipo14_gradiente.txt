import numpy as np
import copy
from numpy import linalg as LA
import matplotlib.pyplot as plt

def fun(x1, x2, x3):
    return x1 * x2 * np.exp(np.power(x1, 2) + np.power(x3, 2) - 5)

def gradient(x1, x2, h):
    return (x1 - x2) / h

xo = [1, 3, -2]
real_gradient = [9, 1, -12]

ls = []

for i in range(1,17):
    ls.append(10**-i)

final = []
for i in ls:
    gradient = []
    for j in range(len(xo)):
        l1 = copy.deepcopy(xo)
        l1[j] = l1[j] + i
        gradiente_j = (fun(l1[0], l1[1], l1[2]) - fun(xo[0], xo[1], xo[2])) / i
        gradient.append(gradiente_j)
    error_r = LA.norm(np.array(gradient) - np.array(real_gradient)) / LA.norm(real_gradient)
    final.append(np.log(error_r))


log_ls = np.log(ls)
plt.plot(log_ls, final)
plt.grid()
plt.xlabel("Log h")
plt.ylabel("Log relative error")